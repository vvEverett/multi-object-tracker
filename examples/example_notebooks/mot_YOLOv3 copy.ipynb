{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple object tracking with YOLOv3-based object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from motrackers.detectors import nanodet\n",
    "from motrackers import CentroidTracker, CentroidKF_Tracker, SORT, IOUTracker\n",
    "from motrackers.utils import draw_tracks\n",
    "from nanodet.util import Logger, cfg, load_config, load_model_weight\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_FILE = r\"D:\\shijue\\LiquidDrop\\22.avi\"\n",
    "WEIGHTS_PATH = r'D:\\shijue\\multi-object-tracker\\weight\\LiquidV4.pth'\n",
    "CONFIG_FILE_PATH = r'D:\\shijue\\multi-object-tracker\\config\\LiquidDetect416.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a5b23e8af54b2aae7a0234a88ab351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='MOTracker:', options=('CentroidTracker', 'CentroidKF_Tracker', 'SORT', 'IOUTracker'), valu…"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_tracker = widgets.Select(\n",
    "    options=[\"CentroidTracker\", \"CentroidKF_Tracker\", \"SORT\", \"IOUTracker\"],\n",
    "    value='CentroidTracker',\n",
    "    rows=5,\n",
    "    description='MOTracker:',\n",
    "    disabled=False\n",
    ")\n",
    "chosen_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if chosen_tracker.value == 'CentroidTracker':\n",
    "    tracker = CentroidTracker(max_lost=0, tracker_output_format='mot_challenge')\n",
    "elif chosen_tracker.value == 'CentroidKF_Tracker':\n",
    "    tracker = CentroidKF_Tracker(max_lost=0, tracker_output_format='mot_challenge')\n",
    "elif chosen_tracker.value == 'SORT':\n",
    "    tracker = SORT(max_lost=3, tracker_output_format='mot_challenge', iou_threshold=0.3)\n",
    "elif chosen_tracker.value == 'IOUTracker':\n",
    "    tracker = IOUTracker(max_lost=2, iou_threshold=0.5, min_detection_confidence=0.4, max_detection_confidence=0.7,\n",
    "                         tracker_output_format='mot_challenge')\n",
    "else:\n",
    "    print(\"Please choose one tracker from the above list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size is  1.0x\n",
      "init weights...\n",
      "=> loading pretrained model https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\n",
      "Finish initialize NanoDet-Plus Head.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[35m[root]\u001b[0m\u001b[34m[04-10 20:46:36]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[37mPress \"Esc\", \"q\" or \"Q\" to exit.\u001b[0m\n",
      "\u001b[1m\u001b[35m[root]\u001b[0m\u001b[34m[04-10 20:46:36]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[37mPress \"Esc\", \"q\" or \"Q\" to exit.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 导入模型文件\n",
    "local_rank = 0\n",
    "model = WEIGHTS_PATH\n",
    "device = \"cpu:0\"\n",
    "config = CONFIG_FILE_PATH\n",
    "logger = Logger(local_rank, use_tensorboard=False)\n",
    "load_config(cfg, config)\n",
    "detmodel = nanodet.Nanodet(cfg, model, logger, device)\n",
    "logger.log('Press \"Esc\", \"q\" or \"Q\" to exit.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main(video_path, model, tracker):\n",
    "\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    while True:\n",
    "        ok, image = cap.read()\n",
    "\n",
    "        if not ok:\n",
    "            print(\"Cannot read the video feed.\")\n",
    "            break\n",
    "        \n",
    "        meta, res = detmodel.inference(image)\n",
    "        bboxes, confidences, class_ids = detmodel.visualize(res[0], meta, cfg.class_names, 0.43)\n",
    "        \n",
    "        tracks = tracker.update(bboxes, confidences, class_ids)\n",
    "        \n",
    "        updated_image = detmodel.draw_bboxes(image.copy(), bboxes, confidences, class_ids)\n",
    "\n",
    "        updated_image = draw_tracks(updated_image, tracks)\n",
    "\n",
    "        cv.imshow(\"image\", updated_image)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward time: 0.146s | decode time: 0.004s | viz time: 0.000s\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Nanodet' object has no attribute 'draw_bboxes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m main(VIDEO_FILE, model, tracker)\n",
      "Cell \u001b[1;32mIn[13], line 16\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(video_path, model, tracker)\u001b[0m\n\u001b[0;32m     12\u001b[0m bboxes, confidences, class_ids \u001b[39m=\u001b[39m detmodel\u001b[39m.\u001b[39mvisualize(res[\u001b[39m0\u001b[39m], meta, cfg\u001b[39m.\u001b[39mclass_names, \u001b[39m0.43\u001b[39m)\n\u001b[0;32m     14\u001b[0m tracks \u001b[39m=\u001b[39m tracker\u001b[39m.\u001b[39mupdate(bboxes, confidences, class_ids)\n\u001b[1;32m---> 16\u001b[0m updated_image \u001b[39m=\u001b[39m detmodel\u001b[39m.\u001b[39;49mdraw_bboxes(image\u001b[39m.\u001b[39mcopy(), bboxes, confidences, class_ids)\n\u001b[0;32m     18\u001b[0m updated_image \u001b[39m=\u001b[39m draw_tracks(updated_image, tracks)\n\u001b[0;32m     20\u001b[0m cv\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m, updated_image)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Nanodet' object has no attribute 'draw_bboxes'"
     ]
    }
   ],
   "source": [
    "main(VIDEO_FILE, model, tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
